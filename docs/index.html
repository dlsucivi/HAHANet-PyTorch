<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>HAHANet-PyTorch | DLSU CIVI</title>

	<link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@300;600&family=Raleway:wght@300;400;500;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700;900&display=swap" rel="stylesheet">
    <link href="https://fonts.cdnfonts.com/css/avenir" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="index.css">
    <link rel="stylesheet" href="https://maxst.icons8.com/vue-static/landings/line-awesome/line-awesome/1.3.0/css/line-awesome.min.css">
    <link href="https://cdn.lineicons.com/4.0/lineicons.css" rel="stylesheet" />
</head>
<body>
    <div id="container">
        <div id="header">
            <h1 id="header-title">HAHANet <br> Towards Accurate Image Classifiers with Less Parameters</h1>
            <div id="header-author-list">
                <h2 class="header-author">Arren Matthew C. Antioquia</h2>
                <h2 class="header-author">Macario Cordel II</h2>
            </div>

            <!-- <nav id="nav-list">
                <a class="link nav-item"> CODE </a>
                <a class="link nav-item"> PAPER </a>
            </nav> -->

            <h3 id="header-publication"> Pacific-Rim Symposium on Image and Video Technology (PSIVT) 2023 </h3>
        </div>

        <div id="content">
            <img id="teaser-img" src="saliency.png">
            <p id="content-abstract">
                Utilizing classical convolutional networks results in lackluster performance in certain classification tasks. To address this problem, recent solutions add extra layers or sub-networks to increase the classification performance of existing networks. More recent methods employ multiple networks coupled with varying learning strategies. However, these approaches demand larger memory and computational requirement due to additional layers, prohibiting usage in devices with limited computing power. In this paper, we propose an efficient convolutional block which minimizes the computational requirements of a network while maintaining information flow through concatenation and element-wise addition. We design a classification architecture, called Half-Append Half-Add Network (HAHANet), built using our efficient convolutional block. Our approach achieves state-of-the-art accuracy on several challenging fine-grained classification tasks. More importantly, HAHANet outperforms top networks while reducing parameter count by at most 54 times. Our code and trained models are publicly available here.
            </p>
        </div>

    </div>

</body>
</html>